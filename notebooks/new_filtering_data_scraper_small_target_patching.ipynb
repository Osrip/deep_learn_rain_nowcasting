{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Todo:\n",
    "\n",
    "Neue Implementation datasamplibg in xarray\n",
    "\n",
    "- [ ] einfach über gesamtes Bild die targets erstellen mit coarsen\n",
    "- [ ] dann nans auf 0 setzen\n",
    "- [ ] durch meinen Filter jagen\n",
    "- [ ] --> diejenigen mit vielen nans werden eh rausgefiltert\n",
    "- [ ] dann wenn das input erstellt wird aus dem target funktion benutzen die einfach nan padded, alles was über die spatial bounds von unserem Datensatz geht (wird wh kaum passieren da unser datensatz ja quasi eh ge nan padded ist)\n",
    "\n",
    "- [ ] Alternativ kann durch strengeres Filterkriterium auch einfach jedes Target mit irgendeinem Pixel als NaN rausgefiltert werden\n",
    "\n",
    "Noch nicht gemacht:\n",
    "\n",
    "AUGMENTATIONS:\n",
    "- aus den Targets werden nur die Input frames erstellt, die dann alle an den data loader weitergegeben werden.\n",
    "    - Diese frames enthalten NaNs, im trainings loop werden dann die NaNs auf 0 gesetzt für die Inputs und die Targets in one hot umgewandelt. \n",
    "- Die Inputs sind etwas größer als 256 x 256 mit einem 'augmentation padding' von ein paar pixeln. \n",
    "    - So kann innerhalb des trainingsloops mit torch random crop das eigentliche target erstellt werden innerhalb des Trainingsloops\n",
    "    - Mit centercrop wird daraus dann das Traget erstellt\n",
    "    - Auch andere image augmentations können genutzt werden ... \n",
    "    - Alle image augmentations (random crop, spiegel, ...) müssen für alle input frames und das target gleich sein! (gleichen seed setzen für random crop?)\n",
    "    ! ACHTUNG ! Die Augmentation findet nicht im data loader statt, sondern erst im Trainings loop! Das Oversampling passiert aber auf dataloader ebene. Ist aber sinnvoll, da sich das Target von der Regenmenge her kaum ändert.\n",
    "\n",
    "STATISTICS!\n",
    "- Wir müssen noch die dataset statistics berechnen! Kann ich einfach schon den gefilterten (also maskierten) Datensatz nehmen und darauf mean und std direkt mit xarray berechnen?\n",
    "\n",
    "ADDITINAL DATA SOURCES\n",
    "\n",
    "- Nutze lat lon und datetime daten in den valid indecvies, sodass auf alle Daten mit dieser Projektion zugegriffen werden kann!\n",
    "\n",
    "old:\n",
    "- Still have to do the nan cropping in xarray: crop in picture such that it is no nan padded\n",
    "- Put all data into RAM (first build calulation tree, with .compute it will be loaded into RAM)\n",
    "- Decide on whether to load the 128 x 128 chunks (because going from 32 x 32 we would indeed have more data but it would be highly correlated so it is questionable whether it boosts performance, but will delay training in prototyping)\n",
    "- Also decide on whether to use every time step as target or directly chunk time into patches with .coarsen()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da511d8a08abfd70"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from datetime import datetime, timedelta\n",
    "import zarr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T12:33:46.454018Z",
     "start_time": "2024-09-03T12:33:46.447639Z"
    }
   },
   "id": "576501505b12811b",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from: /Users/jan/Programming/first_CNN_on_Radolan/dwd_nc/own_test_data/testdata_two_days_2019_01_01-02.zarr\n"
     ]
    }
   ],
   "source": [
    "folder_path = '/Users/jan/Programming/first_CNN_on_Radolan/dwd_nc/own_test_data' #'/home/jan/Programming/remote/first_CNN_on_radolan_remote/dwd_nc/own_test_data'\n",
    "file_name_radolan = 'testdata_two_days_2019_01_01-02.zarr'\n",
    "load_path = os.path.join(folder_path, file_name_radolan)\n",
    "load_path_dem = '/Users/jan/Programming/geo_data/static/dem.zarr'\n",
    "\n",
    "print(f'loading from: {load_path}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T12:33:46.961394Z",
     "start_time": "2024-09-03T12:33:46.958080Z"
    }
   },
   "id": "4ab150c229ac7481",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "num_input_frames = 4\n",
    "lead_time = 4\n",
    "pt = num_input_frames + lead_time # how many time steps to include in a sample (i.e. context and target)\n",
    "# \n",
    "# This defines the size of the patches, that are created by coarsen, filter is applies to these patches\n",
    "py, px = 32, 32 #73, 137 # how many pixels in y and x direction\n",
    "y_input, x_input = 256, 256\n",
    "y_input_padding, x_input_padding = 32, 32\n",
    "threshold_mm_rain_each_pixel = 0.1 # threshold for each pixel filter condition\n",
    "threshold_percentage_pixels = 0.5\n",
    "\n",
    "\n",
    "# In the current implementation py and px define the size of the target patches (previously those were the larger input patches)\n",
    "# length_width_center_even as the same size as py and px, as the filter condition is calculated on the target patches"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T12:33:46.991848Z",
     "start_time": "2024-09-03T12:33:46.986386Z"
    }
   },
   "id": "1a3a8903964bbb8f",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = xr.open_dataset(load_path, engine='zarr') # , chunks=None # , chunks=None according to Sebastian more efficient as it avoids dask (default is chunks=1)\n",
    "# Simply reinstalled environment with numpy pandas xarray zarr jupyter\n",
    "# Now not the same error as in first_CNN_on_Radolan env for some reason\n",
    "data = data.squeeze()\n",
    "# Cut off the beginning  of the data as the size of the data chunk, that one sample has (input frames + lead time + target)\n",
    "data_shortened = data.isel(\n",
    "    time=slice(pt, -1)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T12:33:47.055051Z",
     "start_time": "2024-09-03T12:33:47.040840Z"
    }
   },
   "id": "ffd76fd262be4717",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'+proj=stere +lat_0=90 +lat_ts=90 +lon_0=10 +k=0.93301270189 +x_0=0 +y_0=0 +a=6370040 +b=6370040 +to_meter=1000 +no_defs'"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.dims)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T12:33:47.097600Z",
     "start_time": "2024-09-03T12:33:47.094582Z"
    }
   },
   "id": "b8ae65b601e44f64",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T12:33:47.127406Z",
     "start_time": "2024-09-03T12:33:47.126140Z"
    }
   },
   "id": "ae89e1990767a1e7",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Coordinates:\n    latitude                (y, x) float64 11MB ...\n    longitude               (y, x) float64 11MB ...\n    missing_data_RV_recalc  (time) float32 2kB ...\n    step                    timedelta64[ns] 8B 00:00:00\n  * time                    (time) datetime64[ns] 5kB 2019-01-01T00:40:00 ......\n  * x                       (x) float64 9kB -543.5 -542.5 -541.5 ... 554.5 555.5\n  * y                       (y) float64 10kB -3.61e+03 -3.611e+03 ... -4.809e+03"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_shortened.coords"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T12:33:47.159500Z",
     "start_time": "2024-09-03T12:33:47.155066Z"
    }
   },
   "id": "dab7756463f991b9",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TODO: Crop the beginning of the data, such that we can always generate inputs from the target indecies\n",
    "\n",
    "\n",
    "# partition the data into pt x py x px blocks using coarsen --> construct DatasetCoarsen object\n",
    "# In this implementation each target corresponds to one patch\n",
    "coarse = data_shortened.coarsen(\n",
    "    y = py,\n",
    "    x = px,\n",
    "    # time = 1, # TODO: This way we are making patches with 4 subsequent time frames. This way we are only taking a target every 'pt'th time step\n",
    "    side = \"left\", # \"left\" means that the blocks are aligned to the left of the input\n",
    "    boundary=\"trim\") # boundary=\"trim\" removes the last block if it is too small\n",
    "\n",
    "# construct a new data set, where the patches are folded into a new dimension\n",
    "patches = coarse.construct(\n",
    "    # time = (\"time_outer\", \"time_inner\"),\n",
    "    y = (\"y_outer\", \"y_inner\"),\n",
    "    x = (\"x_outer\", \"x_inner\"))\n",
    "# Replace NaNs with 0s for the filter (we do not have to do this! Makes it less likely for the edge cases to occur in the target.)\n",
    "# We also have the option to filter for NaNs in the input to completely prohibit edge cases\n",
    "patches_no_nan = patches.fillna(0)\n",
    "\n",
    "# --- FILTER ---\n",
    "# define a threshold for each pixel --> we get a pixel-wise boo\n",
    "patches_boolean_pixelwise = patches_no_nan > threshold_mm_rain_each_pixel\n",
    "# We are calculating the percentage of pixels that passed filter (mean of boolean gives percentage of True) \n",
    "# --> we are getting rid of the patch dimensions y_inner and x_inner, \n",
    "patches_percentage_pixels_passed = patches_boolean_pixelwise.mean((\"y_inner\", \"x_inner\")) #, \"time_inner\"\n",
    "# Now we are creating a boolean again by comparing the percentage of pixels that exceed the rain threshold to the minimally required \n",
    "# percentage of pixels that exceed the rain threshold\n",
    "# --> valid_patches includes only the y_outer and x_outer, where each pair of indecies represents one patch. Its values are boolean, indicating whether or not the outer indecies correspond to a valid or invalid patch. \n",
    "valid_patches_boo = patches_percentage_pixels_passed > threshold_percentage_pixels\n",
    "\n",
    "# get the outer coordinates for all valid blocks (valid_time, valid_x, valid_y)\n",
    "# (valid_patches_boo is boolean, np.nonzero returns the indecies of the pixels that are non-zero, thus True)\n",
    "valid_target_indecies_outer = np.array(np.nonzero(valid_patches_boo.RV_recalc.values)).T\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T12:33:54.139301Z",
     "start_time": "2024-09-03T12:33:47.209635Z"
    }
   },
   "id": "9d9556f6cda23401",
   "execution_count": 55
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculate Statistics\n",
    "\n",
    "Somehow only choose the valid patches, flatten the whole data and calc statistics on that!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3e18e16f0681382"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<xarray.Dataset> Size: 3GB\nDimensions:                 (time: 567, y_outer: 37, y_inner: 32, x_outer: 34,\n                             x_inner: 32)\nCoordinates:\n    latitude                (y_outer, y_inner, x_outer, x_inner) float64 10MB ...\n    longitude               (y_outer, y_inner, x_outer, x_inner) float64 10MB ...\n    missing_data_RV_recalc  (time) float32 2kB ...\n    step                    timedelta64[ns] 8B 00:00:00\n  * time                    (time) datetime64[ns] 5kB 2019-01-01T00:40:00 ......\n    x                       (x_outer, x_inner) float64 9kB -543.5 ... 543.5\n    y                       (y_outer, y_inner) float64 9kB -3.61e+03 ... -4.7...\nDimensions without coordinates: y_outer, y_inner, x_outer, x_inner\nData variables:\n    RV_recalc               (time, y_outer, y_inner, x_outer, x_inner) float32 3GB ...\nAttributes:\n    crs:        +proj=stere +lat_0=90 +lat_ts=90 +lon_0=10 +k=0.93301270189 +...\n    nodata:     nan\n    notes:      The grid point RV_recalc[0,0] corresponds to the top-left cor...\n    transform:  [1.0, 0.0, -543.4621669218559, 0.0, -1.0, -3609.644724265573]",
      "text/html": "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n<defs>\n<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n</symbol>\n<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n</symbol>\n</defs>\n</svg>\n<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n *\n */\n\n:root {\n  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n  --xr-background-color: var(--jp-layout-color0, white);\n  --xr-background-color-row-even: var(--jp-layout-color1, white);\n  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n}\n\nhtml[theme=dark],\nhtml[data-theme=dark],\nbody[data-theme=dark],\nbody.vscode-dark {\n  --xr-font-color0: rgba(255, 255, 255, 1);\n  --xr-font-color2: rgba(255, 255, 255, 0.54);\n  --xr-font-color3: rgba(255, 255, 255, 0.38);\n  --xr-border-color: #1F1F1F;\n  --xr-disabled-color: #515151;\n  --xr-background-color: #111111;\n  --xr-background-color-row-even: #111111;\n  --xr-background-color-row-odd: #313131;\n}\n\n.xr-wrap {\n  display: block !important;\n  min-width: 300px;\n  max-width: 700px;\n}\n\n.xr-text-repr-fallback {\n  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n  display: none;\n}\n\n.xr-header {\n  padding-top: 6px;\n  padding-bottom: 6px;\n  margin-bottom: 4px;\n  border-bottom: solid 1px var(--xr-border-color);\n}\n\n.xr-header > div,\n.xr-header > ul {\n  display: inline;\n  margin-top: 0;\n  margin-bottom: 0;\n}\n\n.xr-obj-type,\n.xr-array-name {\n  margin-left: 2px;\n  margin-right: 10px;\n}\n\n.xr-obj-type {\n  color: var(--xr-font-color2);\n}\n\n.xr-sections {\n  padding-left: 0 !important;\n  display: grid;\n  grid-template-columns: 150px auto auto 1fr 20px 20px;\n}\n\n.xr-section-item {\n  display: contents;\n}\n\n.xr-section-item input {\n  display: none;\n}\n\n.xr-section-item input + label {\n  color: var(--xr-disabled-color);\n}\n\n.xr-section-item input:enabled + label {\n  cursor: pointer;\n  color: var(--xr-font-color2);\n}\n\n.xr-section-item input:enabled + label:hover {\n  color: var(--xr-font-color0);\n}\n\n.xr-section-summary {\n  grid-column: 1;\n  color: var(--xr-font-color2);\n  font-weight: 500;\n}\n\n.xr-section-summary > span {\n  display: inline-block;\n  padding-left: 0.5em;\n}\n\n.xr-section-summary-in:disabled + label {\n  color: var(--xr-font-color2);\n}\n\n.xr-section-summary-in + label:before {\n  display: inline-block;\n  content: '►';\n  font-size: 11px;\n  width: 15px;\n  text-align: center;\n}\n\n.xr-section-summary-in:disabled + label:before {\n  color: var(--xr-disabled-color);\n}\n\n.xr-section-summary-in:checked + label:before {\n  content: '▼';\n}\n\n.xr-section-summary-in:checked + label > span {\n  display: none;\n}\n\n.xr-section-summary,\n.xr-section-inline-details {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n.xr-section-inline-details {\n  grid-column: 2 / -1;\n}\n\n.xr-section-details {\n  display: none;\n  grid-column: 1 / -1;\n  margin-bottom: 5px;\n}\n\n.xr-section-summary-in:checked ~ .xr-section-details {\n  display: contents;\n}\n\n.xr-array-wrap {\n  grid-column: 1 / -1;\n  display: grid;\n  grid-template-columns: 20px auto;\n}\n\n.xr-array-wrap > label {\n  grid-column: 1;\n  vertical-align: top;\n}\n\n.xr-preview {\n  color: var(--xr-font-color3);\n}\n\n.xr-array-preview,\n.xr-array-data {\n  padding: 0 5px !important;\n  grid-column: 2;\n}\n\n.xr-array-data,\n.xr-array-in:checked ~ .xr-array-preview {\n  display: none;\n}\n\n.xr-array-in:checked ~ .xr-array-data,\n.xr-array-preview {\n  display: inline-block;\n}\n\n.xr-dim-list {\n  display: inline-block !important;\n  list-style: none;\n  padding: 0 !important;\n  margin: 0;\n}\n\n.xr-dim-list li {\n  display: inline-block;\n  padding: 0;\n  margin: 0;\n}\n\n.xr-dim-list:before {\n  content: '(';\n}\n\n.xr-dim-list:after {\n  content: ')';\n}\n\n.xr-dim-list li:not(:last-child):after {\n  content: ',';\n  padding-right: 5px;\n}\n\n.xr-has-index {\n  font-weight: bold;\n}\n\n.xr-var-list,\n.xr-var-item {\n  display: contents;\n}\n\n.xr-var-item > div,\n.xr-var-item label,\n.xr-var-item > .xr-var-name span {\n  background-color: var(--xr-background-color-row-even);\n  margin-bottom: 0;\n}\n\n.xr-var-item > .xr-var-name:hover span {\n  padding-right: 5px;\n}\n\n.xr-var-list > li:nth-child(odd) > div,\n.xr-var-list > li:nth-child(odd) > label,\n.xr-var-list > li:nth-child(odd) > .xr-var-name span {\n  background-color: var(--xr-background-color-row-odd);\n}\n\n.xr-var-name {\n  grid-column: 1;\n}\n\n.xr-var-dims {\n  grid-column: 2;\n}\n\n.xr-var-dtype {\n  grid-column: 3;\n  text-align: right;\n  color: var(--xr-font-color2);\n}\n\n.xr-var-preview {\n  grid-column: 4;\n}\n\n.xr-index-preview {\n  grid-column: 2 / 5;\n  color: var(--xr-font-color2);\n}\n\n.xr-var-name,\n.xr-var-dims,\n.xr-var-dtype,\n.xr-preview,\n.xr-attrs dt {\n  white-space: nowrap;\n  overflow: hidden;\n  text-overflow: ellipsis;\n  padding-right: 10px;\n}\n\n.xr-var-name:hover,\n.xr-var-dims:hover,\n.xr-var-dtype:hover,\n.xr-attrs dt:hover {\n  overflow: visible;\n  width: auto;\n  z-index: 1;\n}\n\n.xr-var-attrs,\n.xr-var-data,\n.xr-index-data {\n  display: none;\n  background-color: var(--xr-background-color) !important;\n  padding-bottom: 5px !important;\n}\n\n.xr-var-attrs-in:checked ~ .xr-var-attrs,\n.xr-var-data-in:checked ~ .xr-var-data,\n.xr-index-data-in:checked ~ .xr-index-data {\n  display: block;\n}\n\n.xr-var-data > table {\n  float: right;\n}\n\n.xr-var-name span,\n.xr-var-data,\n.xr-index-name div,\n.xr-index-data,\n.xr-attrs {\n  padding-left: 25px !important;\n}\n\n.xr-attrs,\n.xr-var-attrs,\n.xr-var-data,\n.xr-index-data {\n  grid-column: 1 / -1;\n}\n\ndl.xr-attrs {\n  padding: 0;\n  margin: 0;\n  display: grid;\n  grid-template-columns: 125px auto;\n}\n\n.xr-attrs dt,\n.xr-attrs dd {\n  padding: 0;\n  margin: 0;\n  float: left;\n  padding-right: 10px;\n  width: auto;\n}\n\n.xr-attrs dt {\n  font-weight: normal;\n  grid-column: 1;\n}\n\n.xr-attrs dt:hover span {\n  display: inline-block;\n  background: var(--xr-background-color);\n  padding-right: 10px;\n}\n\n.xr-attrs dd {\n  grid-column: 2;\n  white-space: pre-wrap;\n  word-break: break-all;\n}\n\n.xr-icon-database,\n.xr-icon-file-text2,\n.xr-no-icon {\n  display: inline-block;\n  vertical-align: middle;\n  width: 1em;\n  height: 1.5em !important;\n  stroke-width: 0;\n  stroke: currentColor;\n  fill: currentColor;\n}\n</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt; Size: 3GB\nDimensions:                 (time: 567, y_outer: 37, y_inner: 32, x_outer: 34,\n                             x_inner: 32)\nCoordinates:\n    latitude                (y_outer, y_inner, x_outer, x_inner) float64 10MB ...\n    longitude               (y_outer, y_inner, x_outer, x_inner) float64 10MB ...\n    missing_data_RV_recalc  (time) float32 2kB ...\n    step                    timedelta64[ns] 8B 00:00:00\n  * time                    (time) datetime64[ns] 5kB 2019-01-01T00:40:00 ......\n    x                       (x_outer, x_inner) float64 9kB -543.5 ... 543.5\n    y                       (y_outer, y_inner) float64 9kB -3.61e+03 ... -4.7...\nDimensions without coordinates: y_outer, y_inner, x_outer, x_inner\nData variables:\n    RV_recalc               (time, y_outer, y_inner, x_outer, x_inner) float32 3GB ...\nAttributes:\n    crs:        +proj=stere +lat_0=90 +lat_ts=90 +lon_0=10 +k=0.93301270189 +...\n    nodata:     nan\n    notes:      The grid point RV_recalc[0,0] corresponds to the top-left cor...\n    transform:  [1.0, 0.0, -543.4621669218559, 0.0, -1.0, -3609.644724265573]</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-313f8c6e-ee72-4b23-a7c5-7ac97ac43fc6' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-313f8c6e-ee72-4b23-a7c5-7ac97ac43fc6' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>time</span>: 567</li><li><span>y_outer</span>: 37</li><li><span>y_inner</span>: 32</li><li><span>x_outer</span>: 34</li><li><span>x_inner</span>: 32</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-34140bf5-04e7-482b-8984-ee8bd02c4cc9' class='xr-section-summary-in' type='checkbox'  checked><label for='section-34140bf5-04e7-482b-8984-ee8bd02c4cc9' class='xr-section-summary' >Coordinates: <span>(7)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>latitude</span></div><div class='xr-var-dims'>(y_outer, y_inner, x_outer, x_inner)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>55.86 55.86 55.86 ... 45.83 45.83</div><input id='attrs-e9ad233a-dea9-4bec-86e9-2bd1fdde5714' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-e9ad233a-dea9-4bec-86e9-2bd1fdde5714' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-f8361885-5f65-4bbd-bc37-732e2b5b1a93' class='xr-var-data-in' type='checkbox'><label for='data-f8361885-5f65-4bbd-bc37-732e2b5b1a93' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[[[55.85713135, 55.85844174, 55.85974978, ..., 55.89417705,\n          55.89541913, 55.89665885],\n         [55.89789621, 55.89913121, 55.90036385, ..., 55.93275121,\n          55.9339176 , 55.93508161],\n         [55.93624326, 55.93740253, 55.93855943, ..., 55.96889827,\n          55.96998865, 55.97107665],\n         ...,\n         [55.97099441, 55.96990623, 55.96881567, ..., 55.93847198,\n          55.9373149 , 55.93615544],\n         [55.93499362, 55.93382943, 55.93266286, ..., 55.90027066,\n          55.89903784, 55.89780267],\n         [55.89656513, 55.89532523, 55.89408297, ..., 55.85965089,\n          55.85834267, 55.8570321 ]],\n\n        [[55.84842015, 55.84973013, 55.85103776, ..., 55.88545409,\n          55.88669577, 55.8879351 ],\n         [55.88917206, 55.89040667, 55.89163891, ..., 55.92401596,\n          55.92518197, 55.92634562],\n         [55.92750689, 55.9286658 , 55.92982233, ..., 55.96015149,\n          55.96124152, 55.96232917],\n...\n         [45.91655743, 45.91578463, 45.91501013, ..., 45.89345578,\n          45.89263368, 45.89180989],\n         [45.89098439, 45.8901572 , 45.88932831, ..., 45.86630714,\n          45.86543078, 45.86455272],\n         [45.86367297, 45.86279152, 45.86190839, ..., 45.83742425,\n          45.83649377, 45.8355616 ]],\n\n        [[45.82740726, 45.82833905, 45.82926916, ..., 45.85374337,\n          45.85462614, 45.85550723],\n         [45.85638662, 45.85726431, 45.85814032, ..., 45.88115193,\n          45.88198047, 45.88280732],\n         [45.88363246, 45.88445591, 45.88527767, ..., 45.90682283,\n          45.907597  , 45.90836946],\n         ...,\n         [45.90831107, 45.90753848, 45.90676418, ..., 45.88521555,\n          45.88439367, 45.88357009],\n         [45.88274481, 45.88191784, 45.88108917, ..., 45.85807409,\n          45.85719796, 45.85632013],\n         [45.85544062, 45.85455941, 45.8536765 , ..., 45.82919884,\n          45.82826861, 45.82733668]]]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>longitude</span></div><div class='xr-var-dims'>(y_outer, y_inner, x_outer, x_inner)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>1.438 1.453 1.469 ... 16.46 16.47</div><input id='attrs-861ed71d-acf6-4650-8e1a-be7f651e6bdd' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-861ed71d-acf6-4650-8e1a-be7f651e6bdd' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-6cd87bb4-c215-469c-a0a7-8c530c66f2e3' class='xr-var-data-in' type='checkbox'><label for='data-6cd87bb4-c215-469c-a0a7-8c530c66f2e3' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[[[ 1.43794961,  1.45347139,  1.46899442, ...,  1.88858636,\n           1.90414392,  1.91970268],\n         [ 1.93526264,  1.9508238 ,  1.96638616, ...,  2.38701368,\n           2.40260863,  2.41820471],\n         [ 2.43380191,  2.44940025,  2.46499971, ...,  2.88660274,\n           2.90223283,  2.91786399],\n         ...,\n         [17.0833188 , 17.09894987, 17.11457988, ..., 17.53618068,\n          17.55178005, 17.56737831],\n         [17.58297543, 17.59857142, 17.61416628, ..., 18.03479143,\n          18.05035369, 18.06591476],\n         [18.08147463, 18.0970333 , 18.11259077, ..., 18.53218019,\n          18.54770313, 18.56322481]],\n\n        [[ 1.44028582,  1.45580348,  1.47132241, ...,  1.89080301,\n           1.90635643,  1.92191105],\n         [ 1.93746687,  1.95302389,  1.9685821 , ...,  2.38909745,\n           2.40468822,  2.42028013],\n         [ 2.43587317,  2.45146734,  2.46706263, ...,  2.88855269,\n           2.90417858,  2.91980554],\n...\n         [15.34777824, 15.35963158, 15.37148445, ..., 15.69133464,\n          15.70317423, 15.71501334],\n         [15.72685195, 15.73869008, 15.75052771, ..., 16.06995445,\n          16.08177792, 16.09360088],\n         [16.10542331, 16.11724522, 16.12906661, ..., 16.4480429 ,\n          16.45984926, 16.47165506]],\n\n        [[ 3.53057691,  3.54238036,  3.55418436, ...,  3.87309679,\n           3.88491581,  3.89673535],\n         [ 3.90855541,  3.92037599,  3.93219709, ...,  4.25155962,\n           4.26339487,  4.27523061],\n         [ 4.28706685,  4.29890357,  4.31074078, ...,  4.63052643,\n           4.64237691,  4.65422786],\n         ...,\n         [15.34666887, 15.35851978, 15.37037023, ..., 15.69015491,\n          15.70199209, 15.71382877],\n         [15.72566497, 15.73750067, 15.74933589, ..., 16.06869739,\n          16.08051845, 16.09233899],\n         [16.10415901, 16.11597851, 16.12779749, ..., 16.44670883,\n          16.45851278, 16.47031618]]]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>missing_data_RV_recalc</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-f15c8ad5-e3d7-45f1-a8f1-fca5118ac5b7' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-f15c8ad5-e3d7-45f1-a8f1-fca5118ac5b7' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-fb7848f4-1b1c-4803-8bf6-b58656c31381' class='xr-var-data-in' type='checkbox'><label for='data-fb7848f4-1b1c-4803-8bf6-b58656c31381' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>[567 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>step</span></div><div class='xr-var-dims'>()</div><div class='xr-var-dtype'>timedelta64[ns]</div><div class='xr-var-preview xr-preview'>00:00:00</div><input id='attrs-245acf00-d3a2-4dd9-b04b-db033d0849fb' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-245acf00-d3a2-4dd9-b04b-db033d0849fb' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-00b06d7b-9323-4287-8009-56250d3d1d36' class='xr-var-data-in' type='checkbox'><label for='data-00b06d7b-9323-4287-8009-56250d3d1d36' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array(0, dtype=&#x27;timedelta64[ns]&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2019-01-01T00:40:00 ... 2019-01-...</div><input id='attrs-d01d7d3e-133a-40b5-8ffb-7bf9cddd6bed' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-d01d7d3e-133a-40b5-8ffb-7bf9cddd6bed' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-2b1f12d0-d4b9-4576-b7f6-7ec865dc24a3' class='xr-var-data-in' type='checkbox'><label for='data-2b1f12d0-d4b9-4576-b7f6-7ec865dc24a3' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;2019-01-01T00:40:00.000000000&#x27;, &#x27;2019-01-01T00:45:00.000000000&#x27;,\n       &#x27;2019-01-01T00:50:00.000000000&#x27;, ..., &#x27;2019-01-02T23:40:00.000000000&#x27;,\n       &#x27;2019-01-02T23:45:00.000000000&#x27;, &#x27;2019-01-02T23:50:00.000000000&#x27;],\n      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>x</span></div><div class='xr-var-dims'>(x_outer, x_inner)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>-543.5 -542.5 ... 542.5 543.5</div><input id='attrs-d699a00a-98a3-4cf5-b0d6-af2c90ffb40e' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-d699a00a-98a3-4cf5-b0d6-af2c90ffb40e' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-5163016c-e7a2-4306-b571-00759e9dbbff' class='xr-var-data-in' type='checkbox'><label for='data-5163016c-e7a2-4306-b571-00759e9dbbff' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[-543.46216692, -542.46216692, -541.46216692, ..., -514.46216692,\n        -513.46216692, -512.46216692],\n       [-511.46216692, -510.46216692, -509.46216692, ..., -482.46216692,\n        -481.46216692, -480.46216692],\n       [-479.46216692, -478.46216692, -477.46216692, ..., -450.46216692,\n        -449.46216692, -448.46216692],\n       ...,\n       [ 448.53783308,  449.53783308,  450.53783308, ...,  477.53783308,\n         478.53783308,  479.53783308],\n       [ 480.53783308,  481.53783308,  482.53783308, ...,  509.53783308,\n         510.53783308,  511.53783308],\n       [ 512.53783308,  513.53783308,  514.53783308, ...,  541.53783308,\n         542.53783308,  543.53783308]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>y</span></div><div class='xr-var-dims'>(y_outer, y_inner)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>-3.61e+03 -3.611e+03 ... -4.793e+03</div><input id='attrs-6421a17d-2468-405c-9132-cf094355efd4' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-6421a17d-2468-405c-9132-cf094355efd4' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-7027599c-675c-4207-958c-67adac954d0b' class='xr-var-data-in' type='checkbox'><label for='data-7027599c-675c-4207-958c-67adac954d0b' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[-3609.64472427, -3610.64472427, -3611.64472427, ...,\n        -3638.64472427, -3639.64472427, -3640.64472427],\n       [-3641.64472427, -3642.64472427, -3643.64472427, ...,\n        -3670.64472427, -3671.64472427, -3672.64472427],\n       [-3673.64472427, -3674.64472427, -3675.64472427, ...,\n        -3702.64472427, -3703.64472427, -3704.64472427],\n       ...,\n       [-4697.64472427, -4698.64472427, -4699.64472427, ...,\n        -4726.64472427, -4727.64472427, -4728.64472427],\n       [-4729.64472427, -4730.64472427, -4731.64472427, ...,\n        -4758.64472427, -4759.64472427, -4760.64472427],\n       [-4761.64472427, -4762.64472427, -4763.64472427, ...,\n        -4790.64472427, -4791.64472427, -4792.64472427]])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-419b866f-f174-4821-8777-7a6dee04d525' class='xr-section-summary-in' type='checkbox'  checked><label for='section-419b866f-f174-4821-8777-7a6dee04d525' class='xr-section-summary' >Data variables: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>RV_recalc</span></div><div class='xr-var-dims'>(time, y_outer, y_inner, x_outer, x_inner)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>nan nan nan nan ... nan nan nan nan</div><input id='attrs-fdc2e14c-7dd8-43dc-9ab7-c585887546c9' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-fdc2e14c-7dd8-43dc-9ab7-c585887546c9' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e752c922-074f-46ba-90d6-3a2e36673dc5' class='xr-var-data-in' type='checkbox'><label for='data-e752c922-074f-46ba-90d6-3a2e36673dc5' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[[[[nan, nan, nan, ..., nan, nan, nan],\n          [nan, nan, nan, ..., nan, nan, nan],\n          [nan, nan, nan, ..., nan, nan, nan],\n          ...,\n          [nan, nan, nan, ..., nan, nan, nan],\n          [nan, nan, nan, ..., nan, nan, nan],\n          [nan, nan, nan, ..., nan, nan, nan]],\n\n         [[nan, nan, nan, ..., nan, nan, nan],\n          [nan, nan, nan, ..., nan, nan, nan],\n          [nan, nan, nan, ..., nan, nan, nan],\n          ...,\n          [nan, nan, nan, ..., nan, nan, nan],\n          [nan, nan, nan, ..., nan, nan, nan],\n          [nan, nan, nan, ..., nan, nan, nan]],\n\n         [[nan, nan, nan, ..., nan, nan, nan],\n          [nan, nan, nan, ..., nan, nan, nan],\n          [nan, nan, nan, ..., nan, nan, nan],\n          ...,\n...\n          ...,\n          [nan, nan, nan, ..., nan, nan, nan],\n          [nan, nan, nan, ..., nan, nan, nan],\n          [nan, nan, nan, ..., nan, nan, nan]],\n\n         [[nan, nan, nan, ..., nan, nan, nan],\n          [nan, nan, nan, ..., nan, nan, nan],\n          [nan, nan, nan, ..., nan, nan, nan],\n          ...,\n          [nan, nan, nan, ..., nan, nan, nan],\n          [nan, nan, nan, ..., nan, nan, nan],\n          [nan, nan, nan, ..., nan, nan, nan]],\n\n         [[nan, nan, nan, ..., nan, nan, nan],\n          [nan, nan, nan, ..., nan, nan, nan],\n          [nan, nan, nan, ..., nan, nan, nan],\n          ...,\n          [nan, nan, nan, ..., nan, nan, nan],\n          [nan, nan, nan, ..., nan, nan, nan],\n          [nan, nan, nan, ..., nan, nan, nan]]]]], dtype=float32)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-16deb2d0-ae0d-4e49-adbd-25cc52121693' class='xr-section-summary-in' type='checkbox'  ><label for='section-16deb2d0-ae0d-4e49-adbd-25cc52121693' class='xr-section-summary' >Indexes: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-80e7f790-16e9-4567-9f0b-5821f9455eb1' class='xr-index-data-in' type='checkbox'/><label for='index-80e7f790-16e9-4567-9f0b-5821f9455eb1' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;2019-01-01 00:40:00&#x27;, &#x27;2019-01-01 00:45:00&#x27;,\n               &#x27;2019-01-01 00:50:00&#x27;, &#x27;2019-01-01 00:55:00&#x27;,\n               &#x27;2019-01-01 01:00:00&#x27;, &#x27;2019-01-01 01:05:00&#x27;,\n               &#x27;2019-01-01 01:10:00&#x27;, &#x27;2019-01-01 01:15:00&#x27;,\n               &#x27;2019-01-01 01:20:00&#x27;, &#x27;2019-01-01 01:25:00&#x27;,\n               ...\n               &#x27;2019-01-02 23:05:00&#x27;, &#x27;2019-01-02 23:10:00&#x27;,\n               &#x27;2019-01-02 23:15:00&#x27;, &#x27;2019-01-02 23:20:00&#x27;,\n               &#x27;2019-01-02 23:25:00&#x27;, &#x27;2019-01-02 23:30:00&#x27;,\n               &#x27;2019-01-02 23:35:00&#x27;, &#x27;2019-01-02 23:40:00&#x27;,\n               &#x27;2019-01-02 23:45:00&#x27;, &#x27;2019-01-02 23:50:00&#x27;],\n              dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;time&#x27;, length=567, freq=None))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-f2545a91-893e-4842-8931-f43a3c49f9ad' class='xr-section-summary-in' type='checkbox'  checked><label for='section-f2545a91-893e-4842-8931-f43a3c49f9ad' class='xr-section-summary' >Attributes: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>crs :</span></dt><dd>+proj=stere +lat_0=90 +lat_ts=90 +lon_0=10 +k=0.93301270189 +x_0=0 +y_0=0 +a=6370040 +b=6370040 +to_meter=1000 +no_defs</dd><dt><span>nodata :</span></dt><dd>nan</dd><dt><span>notes :</span></dt><dd>The grid point RV_recalc[0,0] corresponds to the top-left corner. Transform root point is top-left. Grid coordinates indicate the bottom left corner of the pixel. The data values were interpolated if the time values of the dataset did not match the desired time values.</dd><dt><span>transform :</span></dt><dd>[1.0, 0.0, -543.4621669218559, 0.0, -1.0, -3609.644724265573]</dd></dl></div></li></ul></div></div>"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T12:33:54.209760Z",
     "start_time": "2024-09-03T12:33:54.141397Z"
    }
   },
   "id": "462fabbc40f9daaa",
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Only select the filtered patches by using the boolean mask (on data that includes NaNs)\n",
    "only_filtered_data = patches.where(valid_patches_boo, drop=True) # I checked that this actually reduces length of time, y_outer and x_outer\n",
    "only_filtered_data_log = np.log1p(only_filtered_data)\n",
    "# Calculate the mean and standard deviation across all dimensions, ignoring NaNs\n",
    "\n",
    "mean = only_filtered_data.mean(dim=None, skipna=True)\n",
    "std = only_filtered_data.std(dim=None, skipna=True)\n",
    "\n",
    "log_mean = only_filtered_data_log.mean(dim=None, skipna=True)\n",
    "log_std = only_filtered_data_log.std(dim=None, skipna=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-09-03T12:33:54.210710Z"
    }
   },
   "id": "b2d3d8e3697958ed",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "mean.RV_recalc.values, std.RV_recalc.values, log_mean.RV_recalc.values, log_std.RV_recalc.values"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "e5a0d0bd789e23e8",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "mean_filtered_log_data in jetzigem Skript auf Testdaten: 0.09430744498968124 (hier array(0.32245284, dtype=float32),)\n",
    "std_filtered_log_data in jetzigem Skript auf Testdaten: 0.20077288150787354 (hier array(0.31162593)))\n",
    "\n",
    "Was ist anders??? --> vorher wurden nans als 0 gewertet, dadurch ist insb. der kleinere mean zu erklären\n",
    "Außerdem samplen wir hier völlig anders\n",
    "\n",
    "##### Nochmal testen mit nan to 0:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97a1e3d18b9807bb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "only_filtered_data_nan_to_0 = only_filtered_data_log.fillna(0)\n",
    "\n",
    "log_mean_nan_to_0 = only_filtered_data_nan_to_0.mean(dim=None)\n",
    "log_std_nan_to_0 = only_filtered_data_nan_to_0.std(dim=None)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "916b46d89e387699",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "log_mean_nan_to_0.RV_recalc.values, log_std_nan_to_0.RV_recalc.values"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "52f864f16570c78a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Diese Werte sind schon viel näher an dem was wir im Code beobachten. Durch das andere Samplen ist die bestehende Abweochung allerdings zu erwarten"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f961666bbd9b8e2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def normalize(data, log_mean, log_std):\n",
    "    '''\n",
    "    Ln(x+1), then z - normalization\n",
    "    '''\n",
    "    if isinstance(data, torch.Tensor):\n",
    "        return (torch.log1p(data) - log_mean) / log_std\n",
    "    else:\n",
    "        return (np.log1p(data) - log_mean) / log_std # log1p takes natural logarithm of x + 1, numerically stable\n",
    "\n",
    "def inverse_normalize(data, log_mean, log_std):\n",
    "    '''\n",
    "    Assumes ln(x+1), then z - normalization\n",
    "    '''\n",
    "    if isinstance(data, torch.Tensor):\n",
    "        return torch.expm1(data * log_std + log_mean)\n",
    "    else:\n",
    "        return np.expm1(data * log_std + log_mean)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "aafceade5bceb567",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Test normalize and inv normalize"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f289e140680dec6b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "patches_log_normalized = normalize(patches, log_mean, log_std)\n",
    "patches_back_to_normal = inverse_normalize(patches_log_normalized, log_mean, log_std)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "227864c51e5e504d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "close = np.isclose(patches.RV_recalc.values, patches_back_to_normal.RV_recalc.values, equal_nan=True) # relative and absolute tolerance by last to args\n",
    "all_close = np.all(close)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "3f385b240259dcfa",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "all_close"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c585e03ef95e1b9b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "valid_target_indecies_outer"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b02a2d3357801ee3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def valid_indecies_to_global_center_indecies(valid_target_indecies_outer, px, py, x_input, y_input):\n",
    "    '''\n",
    "    This functions converts the 'valid_target_indecies_outer' which give the outer indecies with respect to 'patches' to global indecies that refer to 'data_shortened'\n",
    "    \n",
    "    The time index of the input and output indecies always refer to the target frame, which the filtering was done on!\n",
    "    In order to get the input time frames we have to change the time index in the unshortened dataset where the beginning was not clipped!\n",
    "    '''\n",
    "    valid_target_indecies_global = []\n",
    "    valid_center_indecies_global = []\n",
    "    valid_input_indecies_global = []\n",
    "    \n",
    "    for (time, y_inner, x_inner) in valid_target_indecies_outer:\n",
    "        \n",
    "        y_global_upper = y_inner * py\n",
    "        x_global_left = x_inner * px\n",
    "        \n",
    "        # Calculate the global indecies / slices for the targets\n",
    "        slice_y_global = slice(y_global_upper, y_global_upper + py)\n",
    "        slice_x_global = slice(x_global_left, x_global_left + px)\n",
    "        target_slices = [time, slice_y_global, slice_x_global]\n",
    "        valid_target_indecies_global.append(target_slices)\n",
    "        \n",
    "        # Calculate indecies of the patche's center pixels\n",
    "        center_y_global = y_global_upper + py // 2\n",
    "        center_x_global = x_global_left + px // 2\n",
    "        global_center_indecies = [time, center_y_global, center_x_global]\n",
    "        valid_center_indecies_global.append(global_center_indecies)\n",
    "        \n",
    "        # Calculate the global slices for input\n",
    "        # TODO: make sure this does not go out of bounds, create NAN padding of some sort in case the input size exceeds the nan bounds\n",
    "        y_slice_input = slice(center_y_global - (y_input // 2), center_y_global + (y_input // 2))\n",
    "        x_slice_input = slice(center_x_global - (x_input // 2), center_x_global + (x_input // 2))\n",
    "        input_slices = [time, y_slice_input, x_slice_input]\n",
    "        valid_input_indecies_global.append(input_slices)\n",
    "         \n",
    "    return np.array(valid_input_indecies_global), np.array(valid_target_indecies_global), np.array(valid_center_indecies_global)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f5ca8236fb807388",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "valid_input_indecies_global, valid_target_indecies_global, valid_center_indecies_global = valid_indecies_to_global_center_indecies(valid_target_indecies_outer, px, py, y_input + y_input_padding, x_input + x_input_padding)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b9afd937a084f045",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CONVERT INDECIES TO Coords"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4ed1bd5d5c1596a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# REWRITE TO CONVERT INDECIES TO coords\n",
    "def valid_indecies_to_global_center_indecies(data_shortened, valid_target_indecies_outer, px, py, x_input, y_input):\n",
    "    '''\n",
    "    This functions converts the 'valid_target_indecies_outer' which give the outer indecies with respect to 'patches' to global indecies that refer to 'data_shortened'\n",
    "    \n",
    "    The time index of the input and output indecies always refer to the target frame, which the filtering was done on!\n",
    "    In order to get the input time frames we have to change the time index in the unshortened dataset where the beginning was not clipped!\n",
    "    \n",
    "    The patches where the larger input patch exceeds the bounds of data_shortened are dropped! therefore the outputs are shorter than valid_target_indecies_outer\n",
    "    '''\n",
    "    valid_target_indecies_global = [] \n",
    "    valid_center_indecies_global = []\n",
    "    valid_input_indecies_global = []\n",
    "    valid_input_coords = [] # These are defined \n",
    "    \n",
    "    \n",
    "    num_inputs_exceeding_bounds = 0\n",
    "    \n",
    "    for (time, y_outer, x_outer) in valid_target_indecies_outer:\n",
    "        \n",
    "        y_global_upper = y_outer * py\n",
    "        x_global_left = x_outer * px\n",
    "        \n",
    "        # Calculate the global indecies / slices for the targets\n",
    "        # TODO I think this can be removed in future\n",
    "        slice_y_global = slice(y_global_upper, y_global_upper + py)\n",
    "        slice_x_global = slice(x_global_left, x_global_left + px)\n",
    "        target_slices = [time, slice_y_global, slice_x_global]\n",
    "        \n",
    "        # Calculate indecies of the patche's center pixels\n",
    "        center_y_global = y_global_upper + py // 2\n",
    "        center_x_global = x_global_left + px // 2\n",
    "        global_center_indecies = [time, center_y_global, center_x_global]\n",
    "        \n",
    "        # Calculate the global slices for input\n",
    "        y_slice_input = slice(center_y_global - (y_input // 2), center_y_global + (y_input // 2))\n",
    "        x_slice_input = slice(center_x_global - (x_input // 2), center_x_global + (x_input // 2))\n",
    "        input_slices = [time, y_slice_input, x_slice_input]\n",
    "        \n",
    "        # Check if the larger input exceeds size, if not append the patch indecies / slices to the list\n",
    "        if y_slice_input.start < 0 or y_slice_input.stop >= data_shortened.sizes['y'] or x_slice_input.start < 0 or x_slice_input.stop >= data_shortened.sizes['x']:\n",
    "            num_inputs_exceeding_bounds += 1\n",
    "            continue # Skips the rest of the loop if input frame exceeds dataset bounds\n",
    "                \n",
    "        # Convert indecies to coordinates\n",
    "        # TODO: Is there a better way to do this?\n",
    "        time_datetime = data_shortened.time.isel(time=time).values\n",
    "        \n",
    "        y_coords_input = data_shortened.y.isel(y=y_slice_input).values\n",
    "        x_coords_input = data_shortened.x.isel(x=x_slice_input).values\n",
    "        \n",
    "        y_coords_slices_input = slice(y_coords_input[0], y_coords_input[-1])\n",
    "        x_coords_slices_input = slice(x_coords_input[0], x_coords_input[-1])\n",
    "        \n",
    "        input_coords = [time_datetime, y_coords_slices_input, x_coords_slices_input]\n",
    "    \n",
    "        \n",
    "        valid_target_indecies_global.append(target_slices)\n",
    "        valid_center_indecies_global.append(global_center_indecies)\n",
    "        valid_input_indecies_global.append(input_slices)\n",
    "        valid_input_coords.append(input_coords)\n",
    "        \n",
    "    print(f'{num_inputs_exceeding_bounds} patches dropped as input exceeded spatial data bounds')    \n",
    "    return (\n",
    "        np.array(valid_input_coords),\n",
    "        np.array(valid_input_indecies_global),\n",
    "        np.array(valid_target_indecies_global),\n",
    "        np.array(valid_center_indecies_global))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "21efffbb148bf768",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "valid_input_coords, valid_input_indecies_global, valid_target_indecies_global, valid_center_indecies_global = valid_indecies_to_global_center_indecies(\n",
    "    data_shortened, valid_target_indecies_outer, px, py, y_input + y_input_padding, x_input + x_input_padding)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6b4a789414bcdf8a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "valid_input_coords[0,0]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "13c5983c403e1054",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Load DEM (digital elevation model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43e48cb27d0abeea"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dem_data = xr.open_dataset(load_path_dem, engine='zarr')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "29f60d0876a4e5a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dem_data.crs, data.crs"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "9381cf345de12876",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Why are the transforms different? This means that the data is not compatible.."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3baab1d79d732c0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dem_data.transform, data.transform"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "682964bc8eb62726",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dem_data"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "1961436c6582e90e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "d0e23f665bfd1f8b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dem_vals = dem_data.dem.values\n",
    "plt.figure()\n",
    "plt.imshow(dem_vals, cmap='viridis')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "dd6fc3a2fb326f22",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Radolan not a subset of DEM! CANNOT BE BECAUSE DEM COVERS SMALLER TOTAL AREA COMPARED TO RADOLAN! DEM goes out of bounds when selecting the radolan area! Is this due to different transforms? Is there a correctly transformed DEM to our dataset? Visualize in Valentins Tool!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ed9e0d93d552adb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y_coords_range_radolan = data_shortened.y.isel(y=slice(0,-1)).values\n",
    "x_coords_range_radolan = data_shortened.x.isel(x=slice(0,-1)).values\n",
    "\n",
    "dem_range_radolan = dem_data.sel(\n",
    "    y = y_coords_range_radolan,\n",
    "    x = x_coords_range_radolan\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a72bd6d93b904a34",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get the frames"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e350ea41f0a21377"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_frames_from_coords(input_coord, data, num_input_frames, lead_time, time_step_data_minutes=5):\n",
    "    '''\n",
    "    This function takes in the coordinates 'input_coord' \n",
    "        Each input_coord represents one patch that passed the filter.\n",
    "        The spatial slices in input_coord have the spatial size of the input + the augmentation padding \n",
    "        The temporal datetime point gives the time of the target frame (as the filter was applied to the target)\n",
    "        Therefore to get the inputs we have to go back in time relative to the given time in input_coord (depending on lead time and num_input_frames)\n",
    "    \n",
    "    Returns the input and target patches. Both the input and the target patches are in the size of    \n",
    "    '''\n",
    "\n",
    "    \n",
    "    # Make sure this is an int:\n",
    "    num_input_frames = int(num_input_frames)\n",
    "    lead_time = int(lead_time)\n",
    "    \n",
    "    # extract coordinates / coordinat slices\n",
    "    time, y_slice, x_slice = input_coord\n",
    "    \n",
    "    # TODO: IS LEAD TIME CORRECT? I had to take input 5min * input frame -1 to not choose 4, how about the lead time?\n",
    "    # Go back in time to get the time slice of the input\n",
    "    # in oppose to np or list indexing where the last index is not included, the last index is included when taking the datetime slices,\n",
    "    # therefore num_input_frames - 1!\n",
    "    input_start = time - np.timedelta64(time_step_data_minutes * (num_input_frames -1 + lead_time), 'm')\n",
    "    input_end = time - np.timedelta64(time_step_data_minutes * lead_time, 'm')\n",
    "    \n",
    "    time_slice_input = slice(input_start, input_end)\n",
    "    time_coord_target = time\n",
    "    \n",
    "    # Generate input and output data\n",
    "    input = data.sel(\n",
    "        time = time_slice_input,\n",
    "        y = y_slice,\n",
    "        x = x_slice,\n",
    "    )\n",
    "    input_values = input.RV_recalc.values\n",
    "    \n",
    "    target = data.sel(\n",
    "        time = time_coord_target,\n",
    "        y = y_slice,\n",
    "        x = x_slice,\n",
    "    )\n",
    "    target_values = target.RV_recalc.values\n",
    "    \n",
    "    return input_values, target_values\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a2ea7d027c395c55",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rand_coord_idx = np.random.randint(0, valid_input_coords.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "ea8d9be816535f62",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "coord = valid_input_coords[rand_coord_idx]\n",
    "input_frames, target_frame = get_frames_from_coords(coord, data, num_input_frames, lead_time)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "d0523b14b26f8b06",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Augment the frames"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c5595e1329e0c34"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def random_crop(input_frames: torch.Tensor, target_frame: torch.Tensor, crop_size: tuple):\n",
    "    # Assuming input_frames is a list of frames where each frame is a PIL image\n",
    "    # and target_frame is a single PIL image of the same dimensions.\n",
    "    \n",
    "    # Calculate crop parameters for one frame\n",
    "    i, j, h, w = transforms.RandomCrop.get_params(\n",
    "        target_frame, output_size=crop_size)\n",
    "\n",
    "    # Apply the same crop to all frames\n",
    "    cropped_input_frames = [TF.crop(frame, i, j, h, w) for frame in input_frames]\n",
    "    cropped_target_frame = TF.crop(target_frame, i, j, h, w)\n",
    "\n",
    "    return cropped_input_frames, cropped_target_frame"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "d9b543f59db4a800",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "7cb41c3aad99d062",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test Stuff"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23c3316fd91ad4b1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Test get_patches_from_coords"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "986f0a4cb851138f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "coord = valid_input_coords[rand_coord_idx]\n",
    "input_frames, target_frame = get_frames_from_coords(coord, data, num_input_frames, lead_time)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "5af0858a1c92754c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "np.timedelta64(5, 'm')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "ba8fefcd5154269f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "coord[0]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f0401ad74120582a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_frames"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "de0c0224498daf07",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "num_frames = input_frames.shape[0]  # This should be 4 as per your description\n",
    "\n",
    "plt.figure(figsize=(10, 5))  # Adjust the figure size as needed\n",
    "for i in range(num_frames):\n",
    "    plt.subplot(1, num_frames, i + 1)  # 1 row, num_frames columns, i+1 is the subplot index\n",
    "    plt.imshow(input_frames[i, :, :], cmap='viridis')  # Show the ith frame\n",
    "    plt.title(f'Frame {i+1}')  # Title for each subplot\n",
    "    plt.axis('off')  # Hide the axis\n",
    "\n",
    "plt.suptitle('Input Frames')  # Super title for the entire figure\n",
    "plt.show()  # Display the plot"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a38b024522f5b5d7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title('Target from get function')\n",
    "plt.imshow(target_frame, cmap='viridis')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c4d7b14d5b4415e2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "3df49156c51aa34f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test cropped images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27be801a5af325ce"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_frames_tensor = torch.from_numpy(input_frames)\n",
    "target_frame_tensor = torch.from_numpy(target_frame)\n",
    "cropped_input_frames, cropped_target_frame = random_crop(input_frames_tensor, target_frame_tensor, (64, 64))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f588756fc381c4d7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "  # This should be 4 as per your description\n",
    "\n",
    "plt.figure(figsize=(10, 5))  # Adjust the figure size as needed\n",
    "for i, frame in enumerate(cropped_input_frames):\n",
    "    plt.subplot(1, len(cropped_input_frames), i + 1)  # 1 row, num_frames columns, i+1 is the subplot index\n",
    "    plt.imshow(frame, cmap='viridis')  # Show the ith frame\n",
    "    plt.title(f'Frame {i+1}')  # Title for each subplot\n",
    "    plt.axis('off')  # Hide the axis\n",
    "\n",
    "plt.suptitle('Input Frames')  # Super title for the entire figure\n",
    "plt.show()  # Display the plot"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a439846c082f96af",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title('Target cropped')\n",
    "plt.imshow(cropped_target_frame, cmap='viridis')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "5b25bd6091675c0e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_frames_tensor = torch.from_numpy(input_frames)\n",
    "target_frame_tensor = torch.from_numpy(target_frame)\n",
    "# cropped_input_frames, cropped_target_frame = random_crop(input_frames_tensor, target_frame_tensor, 256)\n",
    "# Assuming input_frames is a list of frames where each frame is a PIL image\n",
    "# and target_frame is a single PIL image of the same dimensions.\n",
    "\n",
    "# Calculate crop parameters for one frame\n",
    "i, j, h, w = transforms.RandomCrop.get_params(\n",
    "    target_frame_tensor, output_size=256)\n",
    "\n",
    "# Apply the same crop to all frames\n",
    "cropped_input_frames = [TF.crop(frame, i, j, h, w) for frame in input_frames_tensor]\n",
    "cropped_target_frame = TF.crop(target_frame, i, j, h, w)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "933d89a5e0555913",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "transforms.RandomCrop.get_params(target_frame_tensor, output_size=(256, 256))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "5f48a8f0f63a7cc9",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test valid_indecies_to_global_center_indecies"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5504f24e9f8b83e5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "valid_input_indecies_global\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "ca6020d6cd8240",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample_coord = valid_input_coords[rand_coord_idx]\n",
    "# get the block at the sample coordinate. We are operating on the outer coordinates of the coarsed dataset\n",
    "sample_block = data_shortened.sel(\n",
    "    # time_outer = sample_coord[0],\n",
    "    time = sample_coord[0],\n",
    "    y = sample_coord[1],\n",
    "    x = sample_coord[2])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "fcf1d40ec8d5bed5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample_block_vals = sample_block.RV_recalc.values.squeeze()\n",
    "plt.figure()\n",
    "plt.title('Sample inputs from COORDINATES from data_shortened')\n",
    "plt.imshow(sample_block_vals, cmap='viridis')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "e580e9449af49d75",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample_coord = valid_input_coords[rand_coord_idx]\n",
    "# get the block at the sample coordinate. We are operating on the outer coordinates of the coarsed dataset\n",
    "sample_block = data.sel(\n",
    "    # time_outer = sample_coord[0],\n",
    "    time = sample_coord[0],\n",
    "    y = sample_coord[1],\n",
    "    x = sample_coord[2])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "4ea14839149ccece",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample_block_vals = sample_block.RV_recalc.values.squeeze()\n",
    "plt.figure()\n",
    "plt.title('Sample inputs from COORDINATES from data (not shortened)')\n",
    "plt.imshow(sample_block_vals, cmap='viridis')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6fb7fd711c01263a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample_coord = valid_input_indecies_global[rand_coord_idx]\n",
    "# get the block at the sample coordinate. We are operating on the outer coordinates of the coarsed dataset\n",
    "sample_block = data_shortened.isel(\n",
    "    # time_outer = sample_coord[0],\n",
    "    time = sample_coord[0],\n",
    "    y = sample_coord[1],\n",
    "    x = sample_coord[2])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "3acf0081f5843a60",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample_block_vals = sample_block.RV_recalc.values.squeeze()\n",
    "plt.figure()\n",
    "plt.title('Sample inputs globally')\n",
    "plt.imshow(sample_block_vals, cmap='viridis')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "231491e961902107",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample_coord = valid_target_indecies_global[rand_coord_idx]\n",
    "# get the block at the sample coordinate. We are operating on the outer coordinates of the coarsed dataset\n",
    "sample_block = data_shortened.isel(\n",
    "    # time_outer = sample_coord[0],\n",
    "    time = sample_coord[0],\n",
    "    y = sample_coord[1],\n",
    "    x = sample_coord[2])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f48d099e407199b4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample_block_vals = sample_block.RV_recalc.values.squeeze()\n",
    "plt.figure()\n",
    "plt.title('Sample targets globally')\n",
    "plt.imshow(sample_block_vals, cmap='viridis')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6057891a444bb00c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# SAMPLE DIRECTLY THROUGH INNER indecies FROM 'patches'\n",
    "# THIS TEST TURNED OUT POSITIVE BEFORE PATCHES THAT EXCEED BOUNDS WERE DROPPED SO ALL GOOD\n",
    "\n",
    "# For data loading purposes, we can use the valid_indecies to get the corresponding blocks\n",
    "# For example, to get a random block from the valid blocks, we can do the following:\n",
    "# get a random element from the valid coordinates\n",
    "sample_coord = valid_target_indecies_outer[rand_coord_idx]\n",
    "# get the block at the sample coordinate. We are operating on the outer coordinates of the coarsed dataset\n",
    "sample_block = patches.isel(\n",
    "    # time_outer = sample_coord[0],\n",
    "    time = sample_coord[0],\n",
    "    y_outer = sample_coord[1],\n",
    "    x_outer = sample_coord[2])\n",
    "# Squeeze time dimension, which has len 1\n",
    "# sample_block = sample_block.squeeze()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "9633dafc08d20d25",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample_block_vals = sample_block.RV_recalc.values.squeeze()\n",
    "plt.figure()\n",
    "plt.title(\"SAMPLE DIRECTLY THROUGH INNER indecies FROM 'patches'. THIS IS A DIFFERENT PATCH NOW THAT PATCHES GET DROPPED THAT EXCEED BOUNDS\")\n",
    "plt.imshow(sample_block_vals, cmap='viridis')\n",
    "\n",
    "# group by day xarray --> group by day to split in training and validation"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "622524715a7cb163",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test converting indecies to coors"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11be160faa9beda"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "time, y_outer, x_outer = sample_coord\n",
    "\n",
    "y_global_upper = y_outer * py\n",
    "x_global_left = x_outer * px\n",
    "\n",
    "# Calculate the global indecies / slices for the targets\n",
    "slice_y_global = slice(y_global_upper, y_global_upper + py)\n",
    "slice_x_global = slice(x_global_left, x_global_left + px)\n",
    "target_slices = [time, slice_y_global, slice_x_global]\n",
    "\n",
    "# Calculate indecies of the patche's center pixels\n",
    "center_y_global = y_global_upper + py // 2\n",
    "center_x_global = x_global_left + px // 2\n",
    "global_center_indecies = [time, center_y_global, center_x_global]\n",
    "\n",
    "# Calculate the global slices for input\n",
    "# TODO: make sure this does not go out of bounds, create NAN padding of some sort in case the input size exceeds the nan bounds\n",
    "y_slice_input = slice(center_y_global - (y_input // 2), center_y_global + (y_input // 2))\n",
    "x_slice_input = slice(center_x_global - (x_input // 2), center_x_global + (x_input // 2))\n",
    "input_slices = [time, y_slice_input, x_slice_input]\n",
    "\n",
    "# Convert indecies to coordinates\n",
    "patch = data_shortened.isel(\n",
    "    time = time,\n",
    "    y = y_slice_input,\n",
    "    x = x_slice_input,\n",
    ")\n",
    "\n",
    "# Step 1: Extract the coordinate values at the indices\n",
    "time_value = data_shortened.time.isel(time=time).values\n",
    "lat_values = data_shortened.y.isel(y=y_slice_input).values\n",
    "lon_values = data_shortened.x.isel(x=x_slice_input).values\n",
    "\n",
    "# Step 2: Use these values to select data with sel\n",
    "patch_from_coords = data_shortened.sel(\n",
    "    time=time_value,\n",
    "    y=slice(lat_values[0], lat_values[-1]),\n",
    "    x=slice(lon_values[0], lon_values[-1]))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "8a2e1cc0cc92470d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "time_value"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "8530ba3f4246d667",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lat_values"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "bf681f7ee382352b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample_block_vals = patch_from_coords.RV_recalc.values.squeeze()\n",
    "plt.figure()\n",
    "plt.title(\"patch_from_coords\")\n",
    "plt.imshow(sample_block_vals, cmap='viridis')\n",
    "\n",
    "# group by day xarray --> group by day to split in training and validation"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "308bd63793835275",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample_block_vals = patch.RV_recalc.values.squeeze()\n",
    "plt.figure()\n",
    "plt.title(\"patch_from_coords\")\n",
    "plt.imshow(sample_block_vals, cmap='viridis')\n",
    "\n",
    "# group by day xarray --> group by day to split in training and validation"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "ce6fe2e5dc30fb63",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Try to understand data structure\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69ac1561f4d5ee10"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_shortened"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "82144864c6937e60",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Converting between np indecies to coords"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "933e85d028c57155"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "time_value = data_shortened.time.isel(time=500).values\n",
    "y_value = data_shortened.y.isel(y=600).values\n",
    "x_value = data_shortened.x.isel(x=600).values"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6df933552401cbbb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "time_value, y_value, x_value"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "1712563aa9dc89a5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "time_value = data_shortened.time.sel(time=time_value, method='nearest').values\n",
    "y_value = data_shortened.y.sel(y=y_value, method='nearest').values\n",
    "x_value = data_shortened.x.sel(x=x_value, method='nearest').values\n",
    "time_value, y_value, x_value"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "28cba18f59475ade",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_shortened.sel(\n",
    "    time = time_value,\n",
    "    y = y_value,\n",
    "    x = x_value,\n",
    ").RV_recalc.values"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "669d61c803da7069",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_shortened.isel(\n",
    "    time = 500,\n",
    "    y = 600,\n",
    "    x = 600,\n",
    ").RV_recalc.values"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f5970a60504bac86",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### What does transform do?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1086538f5dc539b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_cropped = data_shortened.isel(\n",
    "    time = 0,\n",
    "    y = slice(20, 30),\n",
    "    x = slice(20, 30),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "2d4a82e1131e8e72",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_cropped.transform"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "2fd4a3407d8db58f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_shortened.transform"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "4b1efe215593c924",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transforms are equal for cropped and original data set\n",
    "--> It cannot be that the transform directly converts from np pixel space to coordinates, as when cropping the [0,0] reference changes in the numpy pixel indecies"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b8e533bd3803da5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "a,b,c,d,e,f = data_shortened.transform"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "fc24ea1c98d4a88e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### What does lat / lon do?\n",
    "Comment:\n",
    "X und Y beinhaltet ja die Daten, innerhalb des von uns definierten Koordinatensystems. \n",
    "Ich hätte gedacht dass jeder Datenpunkt innerhalb von x und y ein lat / lon pair haben müsste. \n",
    "Unter 'longitude' hat jeder Datenpunk allerdings ein x, y pair in unserem Koordinatensystem unter 'latitude' hat auch jeder datenpunkt ein x,y pair ... Macht irgendwie keinen Sinn für mich, was hat das mit latitude / longitude zu tun? "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f70a867712e27f0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_shortened.longitude.y[0]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "12de74ba5435dd1b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_shortened.longitude.x[0]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "d2fc8c3aa0f2dc85",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_shortened.latitude[0].y"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "96c657ed38379249",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_shortened.latitude[0].x"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "984a241b70f480d5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "dd6b47d2e99ecd24",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test Filter"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdd800c8a268e94d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Test filter on all samples\n",
    "for i in range(valid_target_indecies_outer.shape[0]):\n",
    "# i = 1\n",
    "    coord = valid_target_indecies_outer[i, :]\n",
    "    block = patches.isel(\n",
    "        time = coord[0],\n",
    "        y_outer = coord[1],\n",
    "        x_outer = coord[2])\n",
    "    block = block.squeeze()\n",
    "    block_vals = block.RV_recalc.values\n",
    "    \n",
    "    pixel_over_thres_ratio = (block_vals > threshold_mm_rain_each_pixel).sum() / len(sample_block_vals)\n",
    "    if pixel_over_thres_ratio < threshold_percentage_pixels:\n",
    "        print(f'Ratio is {pixel_over_thres_ratio} which is below {threshold_percentage_pixels}')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "904746fad8b87f6c",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
